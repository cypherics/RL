{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cypherics/RL/blob/3.2/assignment_3/assignment3_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rr1d-kHohxGL",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3db73f-c918-46c0-84eb-3264d90b78ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari]==0.25.2 in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.25.2) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.25.2) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.25.2) (2.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.25.2) (6.0.0)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]==0.25.2) (5.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.25.2) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.25.2) (2.25.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.25.2) (7.1.2)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.5.4.tar.gz (12 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]==0.25.2) (3.11.0)\n",
            "Collecting libtorrent\n",
            "  Using cached libtorrent-2.0.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.6 MB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.25.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.25.2) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.25.2) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.25.2) (2022.12.7)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.5.4-py3-none-any.whl size=441148 sha256=4e0272ebf46cad52556a0a7190fcb3e9ec99f5c382131e456a600ae0dc20b0fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/60/90/db006a24f232de90641041430b5913a601345c9efc4cb883ea\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: libtorrent, AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.5.4 ale-py-0.7.5 autorom-0.4.2 libtorrent-2.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install gym[atari,accept-rom-license]==0.25.2\n",
        "import sys, os\n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "from gym.spaces import Box\n",
        "from collections import deque\n",
        "\n",
        "\n",
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "\n",
        "class GrayScaleObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs_shape = self.observation_space.shape[:2]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        observation = np.transpose(observation, (2, 0, 1))\n",
        "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
        "        transform = torchvision.transforms.Grayscale()\n",
        "        observation = transform(observation)\n",
        "        return observation\n",
        "\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        self.shape = (shape, shape) if isinstance(shape, int) else tuple(shape)\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        transforms = torchvision.transforms.Compose([torchvision.transforms.Resize(self.shape),\n",
        "                                                     torchvision.transforms.Normalize(0, 255)])\n",
        "        return transforms(observation).squeeze(0)\n",
        "\n",
        "\n",
        "class ExperienceReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "    def store(self, state, next_state, action, reward, done):\n",
        "        state = state.__array__()\n",
        "        next_state = next_state.__array__()\n",
        "        self.memory.append((state, next_state, action, reward, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        # TODO: uniformly sample batches of Tensors for: state, next_state, action, reward, done\n",
        "        # ...\n",
        "\n",
        "\n",
        "        # uniformly get batch with batch_size\n",
        "        sampled_batch = random.sample(self.memory, batch_size)\n",
        "\n",
        "        states = []\n",
        "        next_states = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        dones = []\n",
        "\n",
        "        # save to arrays\n",
        "        for (curr_state, next_state, action, reward, done) in sampled_batch:\n",
        "            states.append(curr_state)\n",
        "            next_states.append(next_state)\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "            dones.append(done)\n",
        "\n",
        "\n",
        "        return  torch.tensor(np.array(states)), \\\n",
        "                torch.tensor(np.array(next_states)), \\\n",
        "                torch.tensor(np.array(actions)), \\\n",
        "                torch.tensor(np.array(rewards)), \\\n",
        "                torch.tensor(np.array(dones))\n"
      ],
      "metadata": {
        "id": "IGCa_JQeiy1F",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gym\n",
        "import numpy as np\n",
        "import copy\n",
        "from gym.wrappers import FrameStack\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "env_rendering = False    # Set to False while training your model on Colab\n",
        "testing_mode = True\n",
        "test_model_directory = '/content/sample_data/ddqn.pth'\n",
        "\n",
        "# Create and preprocess the Space Invaders environment\n",
        "if env_rendering:\n",
        "    env = gym.make(\"ALE/SpaceInvaders-v5\", full_action_space=False, render_mode=\"human\")\n",
        "else:\n",
        "    env = gym.make(\"ALE/SpaceInvaders-v5\", full_action_space=False)\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "env = FrameStack(env, num_stack=4)\n",
        "image_stack, h, w = env.observation_space.shape\n",
        "num_actions = env.action_space.n\n",
        "print('Number of stacked frames: ', image_stack)\n",
        "print('Resized observation space dimensionality: ', h, w)\n",
        "print('Number of available actions by the agent: ', num_actions)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "seed = 61\n",
        "env.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.backends.cudnn.enabled:\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Hyperparameters (to be modified)\n",
        "batch_size = 32\n",
        "alpha = 0.00025\n",
        "gamma = 0.95\n",
        "eps, eps_decay, min_eps = 1.0, 0.999, 0.05\n",
        "buffer = ExperienceReplayMemory(20000)\n",
        "burn_in_phase = 20000\n",
        "sync_target = 30000\n",
        "max_train_frames = 10000\n",
        "max_train_episodes = 100000\n",
        "max_test_episodes = 1000\n",
        "curr_step = 0\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "LOCiUgfBjJYc",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1214564-9d58-4602-fcef-742bb2fbefdc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of stacked frames:  4\n",
            "Resized observation space dimensionality:  84 84\n",
            "Number of available actions by the agent:  6\n",
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def convert(x):\n",
        "    return torch.tensor(x.__array__()).float()\n",
        "\n",
        "\n",
        "class DeepQNet(torch.nn.Module):\n",
        "    def __init__(self, h, w, image_stack, num_actions):\n",
        "        super(DeepQNet, self).__init__()\n",
        "        # TODO: create a convolutional neural network\n",
        "        # ...\n",
        "\n",
        "        # self.conv = torch.nn.Sequential(\n",
        "        #     torch.nn.Conv2d(4, 6, 5),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.MaxPool2d(2,2),\n",
        "        #     torch.nn.Conv2d(6,16,5),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.MaxPool2d(2,2)\n",
        "        # )\n",
        "\n",
        "        # self.out_size = self.get_out(h,w)\n",
        "        # self.fully_connected_layers = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(self.out_size, 128),\n",
        "        #     torch.nn.Linear(128, 64),\n",
        "        #     torch.nn.Linear(64, num_actions)\n",
        "        # )\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=(8, 8), stride=4),\n",
        "            nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(4, 4), stride=2),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=1),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(in_features=7*7*64, out_features=256),\n",
        "            nn.ReLU())\n",
        "        self.fc2 = nn.Linear(in_features=256, out_features=num_actions)\n",
        "\n",
        "    def get_out(self, h,w):\n",
        "        out = self.conv(torch.zeros(1, 4, h, w))\n",
        "        return int(np.prod(out.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: forward pass from the neural network\n",
        "        # ...\n",
        "        out1 = self.conv1(x)\n",
        "        out2 = self.conv2(out1)        \n",
        "        out3 = self.conv3(out2)\n",
        "        out4 = self.fc1(out3.view(-1, 7*7*64))        \n",
        "        out = self.fc2(out4)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TODO: create an online and target DQN (Hint: Use copy.deepcopy() and requires_grad utilities!)\n",
        "# ...\n",
        "online_dqn = DeepQNet(h,w,image_stack, num_actions)\n",
        "target_dqn = copy.deepcopy(online_dqn)\n",
        "online_dqn.to(device)\n",
        "target_dqn.to(device)\n",
        "\n",
        "\n",
        "# TODO: create the appropriate MSE criterion and Adam optimizer\n",
        "# ...\n",
        "optimizer = torch.optim.Adam(online_dqn.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "NNoUgNjujqRX",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy(state, is_training):\n",
        "    global eps\n",
        "    state = convert(state).unsqueeze(0).to(device)\n",
        "    # state = (1, batch, h, w)\n",
        "\n",
        "    #TODO: Implement an epsilon-greedy policy\n",
        "    #...\n",
        "    # state_c = torch.from_numpy(state).float()/255.0\n",
        "    # state = Variable(state).cuda()\n",
        "    \n",
        "    # online_dqn.eval()\n",
        "    # estimate = online_dqn.forward(state).max(dim=1)\n",
        "    \n",
        "    # # with epsilon prob to choose random action else choose argmax Q estimate action\n",
        "    # if random.random() < self.epsilon:\n",
        "    #     return random.randint(0, self.action_number-1)\n",
        "    # else:\n",
        "    #     return estimate[1].data[0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if is_training:\n",
        "            p = online_dqn(state)\n",
        "            # P = (1, 6)\n",
        "            if np.random.rand() < eps:\n",
        "                a = random_action()\n",
        "            else:\n",
        "                a = torch.argmax(p, dim=1).tolist()\n",
        "\n",
        "        else:\n",
        "            p = online_dqn(state)\n",
        "            a = torch.argmax(p, dim=1).tolist()\n",
        "\n",
        "    return convert(np.array(a)).to(device)\n",
        "\n",
        "def random_action():\n",
        "    return np.random.randint(0, num_actions)\n",
        "\n",
        "def compute_loss(state, action, reward, next_state, done):\n",
        "    state = convert(state).to(device)\n",
        "    next_state = convert(next_state).to(device)\n",
        "    action = action.view(-1, 1).to(device)\n",
        "    reward = reward.view(-1, 1).to(device)\n",
        "    done = done.view(-1, 1).to(device)\n",
        "\n",
        "    # TODO: Compute the DQN (or DDQN) loss based on the criterion\n",
        "    # ...\n",
        "\n",
        "    # mse loss\n",
        "    online_dqn.eval()\n",
        "    target_dqn.eval()\n",
        "\n",
        "    # action_new = online_dqn.forward(next_state).max(dim=1)[1].cpu().data.view(-1, 1).to(device)\n",
        "    action_new = torch.argmax(online_dqn.forward(next_state), dim=1).view(-1, 1)\n",
        "    target = target_dqn.forward(next_state)\n",
        "    y_target =  torch.gather(target, dim=1, index=action_new)\n",
        "    y = reward + torch.mul((y_target * (~done)), gamma)\n",
        "\n",
        "\n",
        "    online_dqn.train()\n",
        "    Q = (torch.gather(online_dqn.forward(state), dim=1, index=action))\n",
        "\n",
        "    loss = criterion(input=Q.float(), target=y.float().detach())\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def run_episode(curr_step, buffer, is_training):\n",
        "    global eps\n",
        "    global target_dqn\n",
        "    global online_dqn\n",
        "    episode_reward, episode_loss = 0, 0.\n",
        "    state = env.reset()\n",
        "    \n",
        "    for t in range(max_train_frames):\n",
        "        action = policy(state, is_training)\n",
        "        curr_step += 1\n",
        "        next_state, reward, done, _ = env.step(int(action.item()))\n",
        "        episode_reward += reward\n",
        "\n",
        "        if is_training:\n",
        "            buffer.store(state, next_state, int(action.item()), reward, done)\n",
        "\n",
        "            if curr_step > burn_in_phase:\n",
        "                state_batch, next_state_batch, action_batch, reward_batch, done_batch = buffer.sample(batch_size)\n",
        "\n",
        "                if curr_step % sync_target == 0:\n",
        "                    # TODO: Periodically update your target_dqn at each sync_target frames\n",
        "                    # ...\n",
        "                     target_dqn.load_state_dict(online_dqn.state_dict())\n",
        "\n",
        "                loss = compute_loss(state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                episode_loss += loss.item()\n",
        "\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                episode_loss += compute_loss(state, action.type(torch.int64), torch.tensor(np.array(reward)), next_state, torch.tensor(np.array(done))).item()\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "    \n",
        "\n",
        "    return dict(reward=episode_reward, loss=episode_loss / t), curr_step\n"
      ],
      "metadata": {
        "id": "RO21LQJ6j0WC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_metrics(metrics, episode):\n",
        "    for k, v in episode.items():\n",
        "        metrics[k].append(v)\n",
        "\n",
        "\n",
        "def print_metrics(it, metrics, is_training, window=100):\n",
        "    reward_mean = np.mean(metrics['reward'][-window:])\n",
        "    loss_mean = np.mean(metrics['loss'][-window:])\n",
        "    mode = \"train\" if is_training else \"test\"\n",
        "    print(f\"Episode {it:4d} | {mode:5s} | reward {reward_mean:5.5f} | loss {loss_mean:5.5f}\")\n",
        "\n",
        "\n",
        "def save_checkpoint(curr_step, eps, train_metrics):\n",
        "    save_dict = {'curr_step': curr_step, \n",
        "                 'train_metrics': train_metrics, \n",
        "                 'eps': eps,\n",
        "                 'online_dqn': online_dqn.state_dict(), \n",
        "                 'target_dqn': target_dqn.state_dict()}\n",
        "    torch.save(save_dict, test_model_directory)\n"
      ],
      "metadata": {
        "id": "PEGSGYsQj8Wh",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Plot your train_metrics and test_metrics\n",
        "# ...\n",
        "def plot_metrics(metrics, window=100):\n",
        "    reward = metrics['reward'][-window:]\n",
        "    loss = metrics['loss'][-window:]\n",
        "\n",
        "    reward = [r for idx, r in enumerate(metrics['reward']) if idx % 50 == 0]\n",
        "    loss = [r for idx, r in enumerate(metrics['loss']) if idx % 50 == 0]\n",
        "    epsiodes = np.arange(0, max_train_episodes, 50)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    ax1.plot(epsiodes, reward)\n",
        "    ax2.plot(epsiodes, loss)\n",
        "\n",
        "    ax1.set_xlabel(\"episodes\")\n",
        "    ax2.set_xlabel(\"episodes\")\n",
        "    ax1.set_ylabel(\"reward\")\n",
        "    ax2.set_ylabel(\"loss\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def save_m(inp):\n",
        "    # load json module\n",
        "    import json\n",
        "    import os\n",
        "\n",
        "    # create json object from dictionary\n",
        "    json = json.dumps(inp)\n",
        "\n",
        "    # open file for writing, \"w\" \n",
        "    f = open(os.path.join(r\"/content/sample_data\", \"test_metrics.json\"),\"w\")\n",
        "\n",
        "    # write json object to file\n",
        "    f.write(json)\n",
        "\n",
        "    # close file\n",
        "    f.close()\n"
      ],
      "metadata": {
        "id": "Uy7C4qfWkzXb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = None\n",
        "if testing_mode:\n",
        "    # TODO: Load your saved online_dqn model for evaluation\n",
        "    # ...\n",
        "    loaded_pth_file = torch.load(test_model_directory)\n",
        "    online_dqn = DeepQNet(h,w,image_stack,num_actions)\n",
        "    online_dqn.load_state_dict(loaded_pth_file['online_dqn'])\n",
        "    online_dqn.cuda()\n",
        "    test_metrics = dict(reward=[], loss=[])\n",
        "    for it in range(max_test_episodes):\n",
        "        episode_metrics, curr_step = run_episode(curr_step, buffer, is_training=False)\n",
        "        update_metrics(test_metrics, episode_metrics)\n",
        "        print_metrics(it + 1, test_metrics, is_training=False)\n",
        "        save_m(test_metrics)\n",
        "\n",
        "    metrics = test_metrics\n",
        "else:\n",
        "    print(\"Training\")\n",
        "    train_metrics = dict(reward=[], loss=[])\n",
        "    for it in range(max_train_episodes):\n",
        "        episode_metrics, curr_step = run_episode(curr_step, buffer, is_training=True)\n",
        "        update_metrics(train_metrics, episode_metrics)\n",
        "        if curr_step > burn_in_phase and eps > min_eps:\n",
        "            eps *= eps_decay\n",
        "        if it % 50 == 0:\n",
        "            print_metrics(it, train_metrics, is_training=True)\n",
        "            save_checkpoint(curr_step, eps, train_metrics)\n",
        "\n",
        "        # print(f\"episode: {it} done!\")\n",
        "        save_m(train_metrics)\n",
        "    metrics = train_metrics\n",
        "    # save_m(metrics)"
      ],
      "metadata": {
        "id": "TdhWcoW-kyuF",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96f513a9-5f05-44d2-c91d-1f3442e6dd99"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode    1 | test  | reward 60.00000 | loss 636.51727\n",
            "Episode    2 | test  | reward 272.50000 | loss 820.00025\n",
            "Episode    3 | test  | reward 288.33333 | loss 868.35117\n",
            "Episode    4 | test  | reward 287.50000 | loss 869.31444\n",
            "Episode    5 | test  | reward 287.00000 | loss 862.90092\n",
            "Episode    6 | test  | reward 328.33333 | loss 898.91984\n",
            "Episode    7 | test  | reward 350.71429 | loss 909.96075\n",
            "Episode    8 | test  | reward 343.75000 | loss 913.75689\n",
            "Episode    9 | test  | reward 326.11111 | loss 881.60184\n",
            "Episode   10 | test  | reward 327.00000 | loss 880.44550\n",
            "Episode   11 | test  | reward 307.27273 | loss 893.50273\n",
            "Episode   12 | test  | reward 301.66667 | loss 903.68561\n",
            "Episode   13 | test  | reward 306.53846 | loss 899.05854\n",
            "Episode   14 | test  | reward 311.07143 | loss 880.78079\n",
            "Episode   15 | test  | reward 304.00000 | loss 887.28825\n",
            "Episode   16 | test  | reward 313.12500 | loss 883.39500\n",
            "Episode   17 | test  | reward 311.17647 | loss 899.07958\n",
            "Episode   18 | test  | reward 320.83333 | loss 904.56541\n",
            "Episode   19 | test  | reward 320.00000 | loss 903.76226\n",
            "Episode   20 | test  | reward 322.50000 | loss 918.54409\n",
            "Episode   21 | test  | reward 323.57143 | loss 905.59076\n",
            "Episode   22 | test  | reward 325.45455 | loss 899.86935\n",
            "Episode   23 | test  | reward 324.56522 | loss 900.47713\n",
            "Episode   24 | test  | reward 325.83333 | loss 899.55454\n",
            "Episode   25 | test  | reward 318.40000 | loss 892.30339\n",
            "Episode   26 | test  | reward 325.00000 | loss 898.87347\n",
            "Episode   27 | test  | reward 330.92593 | loss 902.59281\n",
            "Episode   28 | test  | reward 329.28571 | loss 897.37792\n",
            "Episode   29 | test  | reward 327.75862 | loss 898.67187\n",
            "Episode   30 | test  | reward 327.83333 | loss 894.38309\n",
            "Episode   31 | test  | reward 327.90323 | loss 894.68009\n",
            "Episode   32 | test  | reward 334.21875 | loss 894.83388\n",
            "Episode   33 | test  | reward 333.93939 | loss 901.37984\n",
            "Episode   34 | test  | reward 334.55882 | loss 899.76187\n",
            "Episode   35 | test  | reward 335.00000 | loss 898.39521\n",
            "Episode   36 | test  | reward 335.41667 | loss 901.75312\n",
            "Episode   37 | test  | reward 329.72973 | loss 891.01431\n",
            "Episode   38 | test  | reward 330.00000 | loss 890.13437\n",
            "Episode   39 | test  | reward 330.64103 | loss 886.93787\n",
            "Episode   40 | test  | reward 330.87500 | loss 886.20365\n",
            "Episode   41 | test  | reward 329.87805 | loss 877.48156\n",
            "Episode   42 | test  | reward 329.28571 | loss 876.66639\n",
            "Episode   43 | test  | reward 333.13953 | loss 874.95895\n",
            "Episode   44 | test  | reward 331.47727 | loss 874.16783\n",
            "Episode   45 | test  | reward 331.66667 | loss 875.58750\n",
            "Episode   46 | test  | reward 327.50000 | loss 870.13177\n",
            "Episode   47 | test  | reward 330.53191 | loss 864.67950\n",
            "Episode   48 | test  | reward 329.37500 | loss 865.07598\n",
            "Episode   49 | test  | reward 325.91837 | loss 864.16409\n",
            "Episode   50 | test  | reward 322.30000 | loss 858.64294\n",
            "Episode   51 | test  | reward 322.74510 | loss 857.10297\n",
            "Episode   52 | test  | reward 322.59615 | loss 853.00863\n",
            "Episode   53 | test  | reward 320.47170 | loss 853.79597\n",
            "Episode   54 | test  | reward 323.51852 | loss 856.67782\n",
            "Episode   55 | test  | reward 319.54545 | loss 852.13785\n",
            "Episode   56 | test  | reward 324.64286 | loss 856.57091\n",
            "Episode   57 | test  | reward 323.77193 | loss 862.48178\n",
            "Episode   58 | test  | reward 323.87931 | loss 862.93684\n",
            "Episode   59 | test  | reward 319.49153 | loss 859.50409\n",
            "Episode   60 | test  | reward 320.50000 | loss 857.90019\n",
            "Episode   61 | test  | reward 318.68852 | loss 855.79123\n",
            "Episode   62 | test  | reward 317.01613 | loss 855.80648\n",
            "Episode   63 | test  | reward 317.61905 | loss 857.03281\n",
            "Episode   64 | test  | reward 317.89062 | loss 857.35468\n",
            "Episode   65 | test  | reward 318.30769 | loss 858.21116\n",
            "Episode   66 | test  | reward 316.06061 | loss 859.71361\n",
            "Episode   67 | test  | reward 316.11940 | loss 859.93000\n",
            "Episode   68 | test  | reward 316.25000 | loss 861.94359\n",
            "Episode   69 | test  | reward 315.21739 | loss 863.57364\n",
            "Episode   70 | test  | reward 314.92857 | loss 866.79782\n",
            "Episode   71 | test  | reward 315.63380 | loss 868.11324\n",
            "Episode   72 | test  | reward 315.76389 | loss 867.80876\n",
            "Episode   73 | test  | reward 315.06849 | loss 867.59661\n",
            "Episode   74 | test  | reward 314.32432 | loss 868.95655\n",
            "Episode   75 | test  | reward 313.60000 | loss 869.20999\n",
            "Episode   76 | test  | reward 316.84211 | loss 869.56452\n",
            "Episode   77 | test  | reward 321.55844 | loss 867.77694\n",
            "Episode   78 | test  | reward 321.73077 | loss 874.92563\n",
            "Episode   79 | test  | reward 324.36709 | loss 875.65068\n",
            "Episode   80 | test  | reward 326.93750 | loss 876.46128\n",
            "Episode   81 | test  | reward 326.29630 | loss 880.08739\n",
            "Episode   82 | test  | reward 326.28049 | loss 880.56595\n",
            "Episode   83 | test  | reward 331.56627 | loss 880.71933\n",
            "Episode   84 | test  | reward 330.05952 | loss 878.27082\n",
            "Episode   85 | test  | reward 330.47059 | loss 878.12907\n",
            "Episode   86 | test  | reward 329.82558 | loss 877.50327\n",
            "Episode   87 | test  | reward 328.90805 | loss 876.81703\n",
            "Episode   88 | test  | reward 329.77273 | loss 876.97860\n",
            "Episode   89 | test  | reward 329.88764 | loss 876.76964\n",
            "Episode   90 | test  | reward 331.61111 | loss 878.07830\n",
            "Episode   91 | test  | reward 331.75824 | loss 875.67560\n",
            "Episode   92 | test  | reward 330.32609 | loss 875.38412\n",
            "Episode   93 | test  | reward 329.73118 | loss 874.12091\n",
            "Episode   94 | test  | reward 329.36170 | loss 874.05703\n",
            "Episode   95 | test  | reward 327.63158 | loss 872.34686\n",
            "Episode   96 | test  | reward 327.03125 | loss 876.26829\n",
            "Episode   97 | test  | reward 326.03093 | loss 878.79456\n",
            "Episode   98 | test  | reward 325.96939 | loss 882.52603\n",
            "Episode   99 | test  | reward 326.01010 | loss 882.41902\n",
            "Episode  100 | test  | reward 327.65000 | loss 883.63948\n",
            "Episode  101 | test  | reward 332.20000 | loss 885.18641\n",
            "Episode  102 | test  | reward 331.10000 | loss 883.49542\n",
            "Episode  103 | test  | reward 329.15000 | loss 879.97643\n",
            "Episode  104 | test  | reward 329.00000 | loss 882.45460\n",
            "Episode  105 | test  | reward 328.90000 | loss 883.85853\n",
            "Episode  106 | test  | reward 326.85000 | loss 879.85295\n",
            "Episode  107 | test  | reward 325.30000 | loss 879.37929\n",
            "Episode  108 | test  | reward 324.95000 | loss 876.04714\n",
            "Episode  109 | test  | reward 328.40000 | loss 879.20962\n",
            "Episode  110 | test  | reward 326.40000 | loss 877.32631\n",
            "Episode  111 | test  | reward 330.90000 | loss 876.71198\n",
            "Episode  112 | test  | reward 331.75000 | loss 875.84765\n",
            "Episode  113 | test  | reward 331.60000 | loss 875.40641\n",
            "Episode  114 | test  | reward 329.20000 | loss 874.50906\n",
            "Episode  115 | test  | reward 329.55000 | loss 877.69027\n",
            "Episode  116 | test  | reward 326.65000 | loss 876.98905\n",
            "Episode  117 | test  | reward 326.80000 | loss 874.64010\n",
            "Episode  118 | test  | reward 323.55000 | loss 872.75247\n",
            "Episode  119 | test  | reward 323.95000 | loss 874.73297\n",
            "Episode  120 | test  | reward 325.10000 | loss 872.60764\n",
            "Episode  121 | test  | reward 324.25000 | loss 875.29269\n",
            "Episode  122 | test  | reward 326.15000 | loss 876.30589\n",
            "Episode  123 | test  | reward 324.70000 | loss 874.71743\n",
            "Episode  124 | test  | reward 322.35000 | loss 871.81387\n",
            "Episode  125 | test  | reward 322.05000 | loss 874.49926\n",
            "Episode  126 | test  | reward 320.00000 | loss 872.89575\n",
            "Episode  127 | test  | reward 318.55000 | loss 870.84937\n",
            "Episode  128 | test  | reward 318.45000 | loss 873.49326\n",
            "Episode  129 | test  | reward 317.75000 | loss 872.74441\n",
            "Episode  130 | test  | reward 317.05000 | loss 873.09690\n",
            "Episode  131 | test  | reward 316.35000 | loss 872.24166\n",
            "Episode  132 | test  | reward 313.65000 | loss 872.05376\n",
            "Episode  133 | test  | reward 313.30000 | loss 868.97595\n",
            "Episode  134 | test  | reward 313.40000 | loss 869.01869\n",
            "Episode  135 | test  | reward 313.05000 | loss 867.46944\n",
            "Episode  136 | test  | reward 312.90000 | loss 865.74910\n",
            "Episode  137 | test  | reward 316.55000 | loss 871.13964\n",
            "Episode  138 | test  | reward 317.65000 | loss 871.11479\n",
            "Episode  139 | test  | reward 316.75000 | loss 869.77341\n",
            "Episode  140 | test  | reward 315.75000 | loss 869.13472\n",
            "Episode  141 | test  | reward 315.90000 | loss 872.53348\n",
            "Episode  142 | test  | reward 315.20000 | loss 877.04231\n",
            "Episode  143 | test  | reward 315.15000 | loss 879.53495\n",
            "Episode  144 | test  | reward 316.40000 | loss 878.07987\n",
            "Episode  145 | test  | reward 315.95000 | loss 877.89325\n",
            "Episode  146 | test  | reward 318.80000 | loss 879.94274\n",
            "Episode  147 | test  | reward 317.10000 | loss 883.31929\n",
            "Episode  148 | test  | reward 318.05000 | loss 883.19184\n",
            "Episode  149 | test  | reward 321.30000 | loss 884.93956\n",
            "Episode  150 | test  | reward 322.15000 | loss 892.39059\n",
            "Episode  151 | test  | reward 320.50000 | loss 890.14524\n",
            "Episode  152 | test  | reward 320.65000 | loss 892.92450\n",
            "Episode  153 | test  | reward 323.40000 | loss 894.12315\n",
            "Episode  154 | test  | reward 323.90000 | loss 893.18360\n",
            "Episode  155 | test  | reward 326.10000 | loss 895.76529\n",
            "Episode  156 | test  | reward 321.35000 | loss 890.67009\n",
            "Episode  157 | test  | reward 320.20000 | loss 887.20165\n",
            "Episode  158 | test  | reward 319.60000 | loss 889.59110\n",
            "Episode  159 | test  | reward 321.65000 | loss 890.98904\n",
            "Episode  160 | test  | reward 320.95000 | loss 892.51638\n",
            "Episode  161 | test  | reward 324.15000 | loss 894.54079\n",
            "Episode  162 | test  | reward 325.90000 | loss 894.41614\n",
            "Episode  163 | test  | reward 323.70000 | loss 892.30382\n",
            "Episode  164 | test  | reward 325.65000 | loss 893.46489\n",
            "Episode  165 | test  | reward 324.80000 | loss 894.14237\n",
            "Episode  166 | test  | reward 325.25000 | loss 893.67170\n",
            "Episode  167 | test  | reward 325.30000 | loss 894.99223\n",
            "Episode  168 | test  | reward 324.15000 | loss 892.15980\n",
            "Episode  169 | test  | reward 325.40000 | loss 889.36173\n",
            "Episode  170 | test  | reward 325.95000 | loss 886.54039\n",
            "Episode  171 | test  | reward 327.60000 | loss 886.27661\n",
            "Episode  172 | test  | reward 327.70000 | loss 886.42530\n",
            "Episode  173 | test  | reward 327.20000 | loss 886.72209\n",
            "Episode  174 | test  | reward 327.65000 | loss 884.54157\n",
            "Episode  175 | test  | reward 328.85000 | loss 882.54129\n",
            "Episode  176 | test  | reward 325.50000 | loss 879.18781\n",
            "Episode  177 | test  | reward 321.95000 | loss 880.40114\n",
            "Episode  178 | test  | reward 321.75000 | loss 874.42598\n",
            "Episode  179 | test  | reward 319.15000 | loss 877.07108\n",
            "Episode  180 | test  | reward 319.15000 | loss 876.71376\n",
            "Episode  181 | test  | reward 322.90000 | loss 873.59352\n",
            "Episode  182 | test  | reward 322.40000 | loss 874.78509\n",
            "Episode  183 | test  | reward 319.60000 | loss 875.16763\n",
            "Episode  184 | test  | reward 321.35000 | loss 876.53053\n",
            "Episode  185 | test  | reward 320.15000 | loss 874.21029\n",
            "Episode  186 | test  | reward 320.70000 | loss 874.68673\n",
            "Episode  187 | test  | reward 322.15000 | loss 876.38910\n",
            "Episode  188 | test  | reward 321.80000 | loss 875.35526\n",
            "Episode  189 | test  | reward 319.60000 | loss 872.72444\n",
            "Episode  190 | test  | reward 318.85000 | loss 869.08657\n",
            "Episode  191 | test  | reward 319.85000 | loss 870.64716\n",
            "Episode  192 | test  | reward 320.85000 | loss 873.32554\n",
            "Episode  193 | test  | reward 321.00000 | loss 876.76376\n",
            "Episode  194 | test  | reward 321.05000 | loss 876.39759\n",
            "Episode  195 | test  | reward 320.85000 | loss 875.03969\n",
            "Episode  196 | test  | reward 321.65000 | loss 871.78706\n",
            "Episode  197 | test  | reward 320.95000 | loss 867.91295\n",
            "Episode  198 | test  | reward 321.10000 | loss 864.40216\n",
            "Episode  199 | test  | reward 319.65000 | loss 862.26859\n",
            "Episode  200 | test  | reward 318.65000 | loss 861.45860\n",
            "Episode  201 | test  | reward 315.40000 | loss 859.37378\n",
            "Episode  202 | test  | reward 316.55000 | loss 861.55102\n",
            "Episode  203 | test  | reward 316.60000 | loss 866.01916\n",
            "Episode  204 | test  | reward 317.20000 | loss 863.77694\n",
            "Episode  205 | test  | reward 319.95000 | loss 864.29124\n",
            "Episode  206 | test  | reward 318.65000 | loss 863.10047\n",
            "Episode  207 | test  | reward 318.10000 | loss 863.97700\n",
            "Episode  208 | test  | reward 318.55000 | loss 865.57237\n",
            "Episode  209 | test  | reward 317.20000 | loss 864.46773\n",
            "Episode  210 | test  | reward 318.80000 | loss 866.65218\n",
            "Episode  211 | test  | reward 316.10000 | loss 865.77285\n",
            "Episode  212 | test  | reward 316.95000 | loss 862.80624\n",
            "Episode  213 | test  | reward 316.40000 | loss 864.34729\n",
            "Episode  214 | test  | reward 318.70000 | loss 867.12402\n",
            "Episode  215 | test  | reward 319.50000 | loss 861.92992\n",
            "Episode  216 | test  | reward 320.45000 | loss 859.76998\n",
            "Episode  217 | test  | reward 322.80000 | loss 859.83519\n",
            "Episode  218 | test  | reward 326.75000 | loss 861.69291\n",
            "Episode  219 | test  | reward 326.15000 | loss 859.13236\n",
            "Episode  220 | test  | reward 324.80000 | loss 856.64323\n",
            "Episode  221 | test  | reward 325.65000 | loss 855.08126\n",
            "Episode  222 | test  | reward 324.55000 | loss 852.58114\n",
            "Episode  223 | test  | reward 328.50000 | loss 853.57588\n",
            "Episode  224 | test  | reward 330.75000 | loss 858.58450\n",
            "Episode  225 | test  | reward 333.50000 | loss 856.65881\n",
            "Episode  226 | test  | reward 336.05000 | loss 855.29052\n",
            "Episode  227 | test  | reward 335.30000 | loss 855.62632\n",
            "Episode  228 | test  | reward 337.15000 | loss 854.20765\n",
            "Episode  229 | test  | reward 338.05000 | loss 854.38308\n",
            "Episode  230 | test  | reward 338.35000 | loss 855.14766\n",
            "Episode  231 | test  | reward 338.65000 | loss 858.99735\n",
            "Episode  232 | test  | reward 339.55000 | loss 862.07055\n",
            "Episode  233 | test  | reward 339.80000 | loss 862.29938\n",
            "Episode  234 | test  | reward 341.00000 | loss 863.65066\n",
            "Episode  235 | test  | reward 340.90000 | loss 865.75795\n",
            "Episode  236 | test  | reward 342.45000 | loss 867.80354\n",
            "Episode  237 | test  | reward 342.40000 | loss 866.61668\n",
            "Episode  238 | test  | reward 343.20000 | loss 867.45964\n",
            "Episode  239 | test  | reward 344.50000 | loss 870.46262\n",
            "Episode  240 | test  | reward 344.40000 | loss 871.57827\n",
            "Episode  241 | test  | reward 347.15000 | loss 871.79982\n",
            "Episode  242 | test  | reward 347.70000 | loss 867.60743\n",
            "Episode  243 | test  | reward 347.65000 | loss 867.14438\n",
            "Episode  244 | test  | reward 348.25000 | loss 868.70610\n",
            "Episode  245 | test  | reward 348.15000 | loss 867.79289\n",
            "Episode  246 | test  | reward 347.80000 | loss 868.81152\n",
            "Episode  247 | test  | reward 349.30000 | loss 868.00869\n",
            "Episode  248 | test  | reward 348.90000 | loss 868.23114\n",
            "Episode  249 | test  | reward 347.90000 | loss 866.10277\n",
            "Episode  250 | test  | reward 349.00000 | loss 863.15889\n",
            "Episode  251 | test  | reward 348.80000 | loss 866.07312\n",
            "Episode  252 | test  | reward 348.65000 | loss 865.32391\n",
            "Episode  253 | test  | reward 347.25000 | loss 862.83563\n",
            "Episode  254 | test  | reward 345.25000 | loss 862.06890\n",
            "Episode  255 | test  | reward 346.90000 | loss 864.04902\n",
            "Episode  256 | test  | reward 349.70000 | loss 865.91503\n",
            "Episode  257 | test  | reward 351.35000 | loss 866.54078\n",
            "Episode  258 | test  | reward 351.30000 | loss 865.77386\n",
            "Episode  259 | test  | reward 352.50000 | loss 866.29139\n",
            "Episode  260 | test  | reward 351.40000 | loss 864.39657\n",
            "Episode  261 | test  | reward 349.60000 | loss 865.43531\n",
            "Episode  262 | test  | reward 352.90000 | loss 865.28027\n",
            "Episode  263 | test  | reward 356.50000 | loss 867.85877\n",
            "Episode  264 | test  | reward 353.85000 | loss 866.96078\n",
            "Episode  265 | test  | reward 356.55000 | loss 866.45784\n",
            "Episode  266 | test  | reward 359.25000 | loss 867.38961\n",
            "Episode  267 | test  | reward 358.90000 | loss 866.42657\n",
            "Episode  268 | test  | reward 359.60000 | loss 866.27329\n",
            "Episode  269 | test  | reward 359.50000 | loss 867.57103\n",
            "Episode  270 | test  | reward 360.45000 | loss 867.60412\n",
            "Episode  271 | test  | reward 358.00000 | loss 868.11218\n",
            "Episode  272 | test  | reward 359.55000 | loss 870.09521\n",
            "Episode  273 | test  | reward 360.85000 | loss 869.12449\n",
            "Episode  274 | test  | reward 361.45000 | loss 870.24835\n",
            "Episode  275 | test  | reward 360.55000 | loss 872.40310\n",
            "Episode  276 | test  | reward 361.35000 | loss 878.97309\n",
            "Episode  277 | test  | reward 361.45000 | loss 880.25509\n",
            "Episode  278 | test  | reward 361.15000 | loss 881.47357\n",
            "Episode  279 | test  | reward 363.75000 | loss 878.41936\n",
            "Episode  280 | test  | reward 363.15000 | loss 878.26245\n",
            "Episode  281 | test  | reward 359.30000 | loss 878.39124\n",
            "Episode  282 | test  | reward 357.65000 | loss 875.50171\n",
            "Episode  283 | test  | reward 355.80000 | loss 875.53668\n",
            "Episode  284 | test  | reward 353.30000 | loss 875.81278\n",
            "Episode  285 | test  | reward 354.25000 | loss 877.26077\n",
            "Episode  286 | test  | reward 354.05000 | loss 877.19573\n",
            "Episode  287 | test  | reward 353.65000 | loss 874.80972\n",
            "Episode  288 | test  | reward 351.50000 | loss 875.80828\n",
            "Episode  289 | test  | reward 355.20000 | loss 879.73973\n",
            "Episode  290 | test  | reward 354.45000 | loss 884.75983\n",
            "Episode  291 | test  | reward 353.15000 | loss 888.30144\n",
            "Episode  292 | test  | reward 352.75000 | loss 887.57414\n",
            "Episode  293 | test  | reward 353.00000 | loss 885.15468\n",
            "Episode  294 | test  | reward 352.90000 | loss 888.05252\n",
            "Episode  295 | test  | reward 353.20000 | loss 889.82502\n",
            "Episode  296 | test  | reward 352.85000 | loss 889.30891\n",
            "Episode  297 | test  | reward 354.20000 | loss 891.26751\n",
            "Episode  298 | test  | reward 355.10000 | loss 890.18400\n",
            "Episode  299 | test  | reward 354.85000 | loss 892.33936\n",
            "Episode  300 | test  | reward 354.20000 | loss 890.85798\n",
            "Episode  301 | test  | reward 355.75000 | loss 893.52371\n",
            "Episode  302 | test  | reward 352.60000 | loss 891.29383\n",
            "Episode  303 | test  | reward 353.90000 | loss 893.47753\n",
            "Episode  304 | test  | reward 355.45000 | loss 893.80528\n",
            "Episode  305 | test  | reward 352.80000 | loss 895.42425\n",
            "Episode  306 | test  | reward 352.40000 | loss 903.42382\n",
            "Episode  307 | test  | reward 353.45000 | loss 901.30750\n",
            "Episode  308 | test  | reward 354.05000 | loss 902.32734\n",
            "Episode  309 | test  | reward 352.50000 | loss 902.43779\n",
            "Episode  310 | test  | reward 355.30000 | loss 902.46210\n",
            "Episode  311 | test  | reward 355.25000 | loss 899.73920\n",
            "Episode  312 | test  | reward 353.90000 | loss 904.87544\n",
            "Episode  313 | test  | reward 355.10000 | loss 901.72207\n",
            "Episode  314 | test  | reward 354.65000 | loss 907.04736\n",
            "Episode  315 | test  | reward 352.90000 | loss 904.75012\n",
            "Episode  316 | test  | reward 353.80000 | loss 911.85988\n",
            "Episode  317 | test  | reward 353.35000 | loss 912.58661\n",
            "Episode  318 | test  | reward 350.10000 | loss 908.13864\n",
            "Episode  319 | test  | reward 351.05000 | loss 909.08242\n",
            "Episode  320 | test  | reward 349.70000 | loss 908.85618\n",
            "Episode  321 | test  | reward 349.25000 | loss 909.06809\n",
            "Episode  322 | test  | reward 349.70000 | loss 913.28906\n",
            "Episode  323 | test  | reward 346.95000 | loss 912.89218\n",
            "Episode  324 | test  | reward 346.65000 | loss 912.60179\n",
            "Episode  325 | test  | reward 345.55000 | loss 914.84943\n",
            "Episode  326 | test  | reward 343.45000 | loss 915.85970\n",
            "Episode  327 | test  | reward 345.65000 | loss 917.64158\n",
            "Episode  328 | test  | reward 346.35000 | loss 918.27324\n",
            "Episode  329 | test  | reward 345.45000 | loss 918.13112\n",
            "Episode  330 | test  | reward 345.95000 | loss 922.32115\n",
            "Episode  331 | test  | reward 345.90000 | loss 918.43990\n",
            "Episode  332 | test  | reward 346.05000 | loss 914.11536\n",
            "Episode  333 | test  | reward 346.10000 | loss 915.17609\n",
            "Episode  334 | test  | reward 344.80000 | loss 913.23424\n",
            "Episode  335 | test  | reward 346.60000 | loss 914.23134\n",
            "Episode  336 | test  | reward 345.00000 | loss 911.07001\n",
            "Episode  337 | test  | reward 343.40000 | loss 910.05111\n",
            "Episode  338 | test  | reward 340.10000 | loss 906.52703\n",
            "Episode  339 | test  | reward 339.50000 | loss 906.18845\n",
            "Episode  340 | test  | reward 339.00000 | loss 905.34585\n",
            "Episode  341 | test  | reward 337.00000 | loss 905.57104\n",
            "Episode  342 | test  | reward 338.15000 | loss 906.31911\n",
            "Episode  343 | test  | reward 336.55000 | loss 904.83065\n",
            "Episode  344 | test  | reward 335.00000 | loss 905.86396\n",
            "Episode  345 | test  | reward 335.45000 | loss 907.55999\n",
            "Episode  346 | test  | reward 334.15000 | loss 906.57345\n",
            "Episode  347 | test  | reward 332.95000 | loss 906.03185\n",
            "Episode  348 | test  | reward 334.25000 | loss 905.94534\n",
            "Episode  349 | test  | reward 332.10000 | loss 907.09207\n",
            "Episode  350 | test  | reward 333.55000 | loss 906.75859\n",
            "Episode  351 | test  | reward 335.40000 | loss 906.92270\n",
            "Episode  352 | test  | reward 335.30000 | loss 907.90377\n",
            "Episode  353 | test  | reward 333.95000 | loss 909.03788\n",
            "Episode  354 | test  | reward 334.25000 | loss 908.80150\n",
            "Episode  355 | test  | reward 332.05000 | loss 906.34606\n",
            "Episode  356 | test  | reward 330.00000 | loss 904.03953\n",
            "Episode  357 | test  | reward 329.00000 | loss 903.39594\n",
            "Episode  358 | test  | reward 328.00000 | loss 900.19564\n",
            "Episode  359 | test  | reward 330.55000 | loss 897.98667\n",
            "Episode  360 | test  | reward 330.95000 | loss 898.73349\n",
            "Episode  361 | test  | reward 330.50000 | loss 896.39899\n",
            "Episode  362 | test  | reward 326.40000 | loss 895.98828\n",
            "Episode  363 | test  | reward 324.30000 | loss 895.56873\n",
            "Episode  364 | test  | reward 323.35000 | loss 892.97995\n",
            "Episode  365 | test  | reward 319.35000 | loss 890.13228\n",
            "Episode  366 | test  | reward 320.95000 | loss 888.44213\n",
            "Episode  367 | test  | reward 323.35000 | loss 888.76850\n",
            "Episode  368 | test  | reward 323.70000 | loss 891.27181\n",
            "Episode  369 | test  | reward 324.95000 | loss 892.93448\n",
            "Episode  370 | test  | reward 325.75000 | loss 893.74075\n",
            "Episode  371 | test  | reward 325.70000 | loss 892.12495\n",
            "Episode  372 | test  | reward 323.70000 | loss 889.36529\n",
            "Episode  373 | test  | reward 322.75000 | loss 887.64218\n",
            "Episode  374 | test  | reward 322.30000 | loss 890.58064\n",
            "Episode  375 | test  | reward 324.25000 | loss 891.64718\n",
            "Episode  376 | test  | reward 324.25000 | loss 888.70913\n",
            "Episode  377 | test  | reward 324.30000 | loss 887.75655\n",
            "Episode  378 | test  | reward 323.75000 | loss 888.44384\n",
            "Episode  379 | test  | reward 321.05000 | loss 892.84914\n",
            "Episode  380 | test  | reward 319.05000 | loss 893.39102\n",
            "Episode  381 | test  | reward 319.60000 | loss 895.24123\n",
            "Episode  382 | test  | reward 321.35000 | loss 895.29302\n",
            "Episode  383 | test  | reward 321.70000 | loss 893.75663\n",
            "Episode  384 | test  | reward 324.05000 | loss 893.27980\n",
            "Episode  385 | test  | reward 323.90000 | loss 895.78296\n",
            "Episode  386 | test  | reward 324.45000 | loss 894.51486\n",
            "Episode  387 | test  | reward 325.05000 | loss 893.99215\n",
            "Episode  388 | test  | reward 326.90000 | loss 893.46499\n",
            "Episode  389 | test  | reward 325.50000 | loss 892.32023\n",
            "Episode  390 | test  | reward 325.15000 | loss 889.07198\n",
            "Episode  391 | test  | reward 325.45000 | loss 883.96569\n",
            "Episode  392 | test  | reward 327.70000 | loss 883.47151\n",
            "Episode  393 | test  | reward 326.15000 | loss 879.82532\n",
            "Episode  394 | test  | reward 326.45000 | loss 875.73916\n",
            "Episode  395 | test  | reward 327.95000 | loss 878.60116\n",
            "Episode  396 | test  | reward 327.65000 | loss 878.55021\n",
            "Episode  397 | test  | reward 327.55000 | loss 877.62652\n",
            "Episode  398 | test  | reward 325.95000 | loss 880.50495\n",
            "Episode  399 | test  | reward 327.35000 | loss 879.87403\n",
            "Episode  400 | test  | reward 328.95000 | loss 881.99318\n",
            "Episode  401 | test  | reward 328.45000 | loss 882.84124\n",
            "Episode  402 | test  | reward 331.55000 | loss 884.59966\n",
            "Episode  403 | test  | reward 334.25000 | loss 881.40569\n",
            "Episode  404 | test  | reward 332.90000 | loss 879.16867\n",
            "Episode  405 | test  | reward 334.45000 | loss 872.54449\n",
            "Episode  406 | test  | reward 336.30000 | loss 869.40219\n",
            "Episode  407 | test  | reward 336.45000 | loss 869.31589\n",
            "Episode  408 | test  | reward 335.75000 | loss 868.29436\n",
            "Episode  409 | test  | reward 339.25000 | loss 870.30239\n",
            "Episode  410 | test  | reward 338.40000 | loss 871.70571\n",
            "Episode  411 | test  | reward 337.90000 | loss 878.87068\n",
            "Episode  412 | test  | reward 338.65000 | loss 876.28480\n",
            "Episode  413 | test  | reward 335.85000 | loss 875.56931\n",
            "Episode  414 | test  | reward 335.60000 | loss 870.94625\n",
            "Episode  415 | test  | reward 336.70000 | loss 874.24584\n",
            "Episode  416 | test  | reward 336.55000 | loss 869.57470\n",
            "Episode  417 | test  | reward 333.30000 | loss 867.87730\n",
            "Episode  418 | test  | reward 333.30000 | loss 873.63023\n",
            "Episode  419 | test  | reward 331.90000 | loss 871.07071\n",
            "Episode  420 | test  | reward 332.90000 | loss 871.67588\n",
            "Episode  421 | test  | reward 332.25000 | loss 877.53130\n",
            "Episode  422 | test  | reward 330.95000 | loss 875.13919\n",
            "Episode  423 | test  | reward 331.50000 | loss 877.69281\n",
            "Episode  424 | test  | reward 331.35000 | loss 876.56253\n",
            "Episode  425 | test  | reward 331.25000 | loss 875.45189\n",
            "Episode  426 | test  | reward 332.80000 | loss 877.03458\n",
            "Episode  427 | test  | reward 330.80000 | loss 874.30491\n",
            "Episode  428 | test  | reward 330.10000 | loss 874.61341\n",
            "Episode  429 | test  | reward 331.30000 | loss 873.65134\n",
            "Episode  430 | test  | reward 331.55000 | loss 868.89792\n",
            "Episode  431 | test  | reward 331.65000 | loss 869.49923\n",
            "Episode  432 | test  | reward 332.90000 | loss 872.38847\n",
            "Episode  433 | test  | reward 332.60000 | loss 870.84798\n",
            "Episode  434 | test  | reward 331.95000 | loss 873.44294\n",
            "Episode  435 | test  | reward 330.00000 | loss 872.45876\n",
            "Episode  436 | test  | reward 328.40000 | loss 873.29913\n",
            "Episode  437 | test  | reward 328.30000 | loss 874.19287\n",
            "Episode  438 | test  | reward 331.05000 | loss 874.31319\n",
            "Episode  439 | test  | reward 331.20000 | loss 872.02365\n",
            "Episode  440 | test  | reward 332.75000 | loss 873.17123\n",
            "Episode  441 | test  | reward 334.25000 | loss 873.64384\n",
            "Episode  442 | test  | reward 332.85000 | loss 874.89012\n",
            "Episode  443 | test  | reward 330.45000 | loss 876.17478\n",
            "Episode  444 | test  | reward 330.70000 | loss 876.71266\n",
            "Episode  445 | test  | reward 329.95000 | loss 876.42447\n",
            "Episode  446 | test  | reward 328.95000 | loss 876.32918\n",
            "Episode  447 | test  | reward 328.70000 | loss 876.04461\n",
            "Episode  448 | test  | reward 327.50000 | loss 875.47127\n",
            "Episode  449 | test  | reward 327.40000 | loss 875.16353\n",
            "Episode  450 | test  | reward 324.55000 | loss 872.56257\n",
            "Episode  451 | test  | reward 323.95000 | loss 872.07039\n",
            "Episode  452 | test  | reward 325.75000 | loss 872.53091\n",
            "Episode  453 | test  | reward 326.85000 | loss 871.14347\n",
            "Episode  454 | test  | reward 326.00000 | loss 870.81624\n",
            "Episode  455 | test  | reward 326.30000 | loss 873.01481\n",
            "Episode  456 | test  | reward 326.90000 | loss 877.02552\n",
            "Episode  457 | test  | reward 328.85000 | loss 876.47838\n",
            "Episode  458 | test  | reward 330.70000 | loss 880.61645\n",
            "Episode  459 | test  | reward 326.35000 | loss 879.47013\n",
            "Episode  460 | test  | reward 325.50000 | loss 877.25662\n",
            "Episode  461 | test  | reward 325.50000 | loss 879.16084\n",
            "Episode  462 | test  | reward 325.85000 | loss 882.13538\n",
            "Episode  463 | test  | reward 327.40000 | loss 881.84753\n",
            "Episode  464 | test  | reward 328.10000 | loss 880.67574\n",
            "Episode  465 | test  | reward 331.65000 | loss 884.44565\n",
            "Episode  466 | test  | reward 328.70000 | loss 886.13066\n",
            "Episode  467 | test  | reward 326.95000 | loss 885.24149\n",
            "Episode  468 | test  | reward 326.40000 | loss 885.48680\n",
            "Episode  469 | test  | reward 324.25000 | loss 885.73675\n",
            "Episode  470 | test  | reward 322.15000 | loss 885.44767\n",
            "Episode  471 | test  | reward 324.20000 | loss 887.16273\n",
            "Episode  472 | test  | reward 324.40000 | loss 889.44621\n",
            "Episode  473 | test  | reward 325.65000 | loss 889.82893\n",
            "Episode  474 | test  | reward 325.30000 | loss 886.03447\n",
            "Episode  475 | test  | reward 322.05000 | loss 882.44521\n",
            "Episode  476 | test  | reward 321.85000 | loss 881.88912\n",
            "Episode  477 | test  | reward 321.55000 | loss 882.96659\n",
            "Episode  478 | test  | reward 322.25000 | loss 882.27916\n",
            "Episode  479 | test  | reward 324.65000 | loss 878.52446\n",
            "Episode  480 | test  | reward 325.00000 | loss 881.30242\n",
            "Episode  481 | test  | reward 327.10000 | loss 879.34393\n",
            "Episode  482 | test  | reward 328.70000 | loss 878.53345\n",
            "Episode  483 | test  | reward 330.25000 | loss 880.66371\n",
            "Episode  484 | test  | reward 330.05000 | loss 880.55422\n",
            "Episode  485 | test  | reward 329.85000 | loss 879.69380\n",
            "Episode  486 | test  | reward 329.70000 | loss 881.11631\n",
            "Episode  487 | test  | reward 327.55000 | loss 881.17849\n",
            "Episode  488 | test  | reward 325.70000 | loss 878.80125\n",
            "Episode  489 | test  | reward 325.25000 | loss 879.19699\n",
            "Episode  490 | test  | reward 325.20000 | loss 878.69391\n",
            "Episode  491 | test  | reward 325.00000 | loss 881.50232\n",
            "Episode  492 | test  | reward 321.55000 | loss 878.48980\n",
            "Episode  493 | test  | reward 324.10000 | loss 880.03366\n",
            "Episode  494 | test  | reward 325.75000 | loss 883.31456\n",
            "Episode  495 | test  | reward 325.65000 | loss 881.34713\n",
            "Episode  496 | test  | reward 325.40000 | loss 884.25272\n",
            "Episode  497 | test  | reward 325.85000 | loss 883.42700\n",
            "Episode  498 | test  | reward 326.00000 | loss 881.66957\n",
            "Episode  499 | test  | reward 326.05000 | loss 882.46759\n",
            "Episode  500 | test  | reward 322.60000 | loss 879.84218\n",
            "Episode  501 | test  | reward 323.30000 | loss 878.85255\n",
            "Episode  502 | test  | reward 322.20000 | loss 876.84791\n",
            "Episode  503 | test  | reward 320.40000 | loss 874.61700\n",
            "Episode  504 | test  | reward 318.00000 | loss 876.24803\n",
            "Episode  505 | test  | reward 317.00000 | loss 879.49327\n",
            "Episode  506 | test  | reward 318.40000 | loss 878.96499\n",
            "Episode  507 | test  | reward 317.75000 | loss 883.40268\n",
            "Episode  508 | test  | reward 316.80000 | loss 883.84133\n",
            "Episode  509 | test  | reward 315.75000 | loss 883.32790\n",
            "Episode  510 | test  | reward 313.95000 | loss 880.20393\n",
            "Episode  511 | test  | reward 314.60000 | loss 878.47802\n",
            "Episode  512 | test  | reward 314.80000 | loss 877.06517\n",
            "Episode  513 | test  | reward 316.30000 | loss 880.02417\n",
            "Episode  514 | test  | reward 314.50000 | loss 880.39264\n",
            "Episode  515 | test  | reward 315.20000 | loss 879.05571\n",
            "Episode  516 | test  | reward 314.50000 | loss 880.02308\n",
            "Episode  517 | test  | reward 319.50000 | loss 878.06949\n",
            "Episode  518 | test  | reward 320.15000 | loss 874.10092\n",
            "Episode  519 | test  | reward 318.65000 | loss 872.63586\n",
            "Episode  520 | test  | reward 319.00000 | loss 874.13883\n",
            "Episode  521 | test  | reward 319.70000 | loss 868.99729\n",
            "Episode  522 | test  | reward 319.05000 | loss 869.85437\n",
            "Episode  523 | test  | reward 318.60000 | loss 871.28205\n",
            "Episode  524 | test  | reward 319.40000 | loss 870.95471\n",
            "Episode  525 | test  | reward 318.30000 | loss 868.24778\n",
            "Episode  526 | test  | reward 316.05000 | loss 866.38706\n",
            "Episode  527 | test  | reward 315.85000 | loss 867.20571\n",
            "Episode  528 | test  | reward 314.40000 | loss 870.16112\n",
            "Episode  529 | test  | reward 314.70000 | loss 870.60163\n",
            "Episode  530 | test  | reward 314.45000 | loss 871.88780\n",
            "Episode  531 | test  | reward 316.35000 | loss 872.83956\n",
            "Episode  532 | test  | reward 316.35000 | loss 872.70333\n",
            "Episode  533 | test  | reward 316.60000 | loss 872.93690\n",
            "Episode  534 | test  | reward 318.55000 | loss 871.67124\n",
            "Episode  535 | test  | reward 318.35000 | loss 870.54838\n",
            "Episode  536 | test  | reward 320.05000 | loss 870.37937\n",
            "Episode  537 | test  | reward 319.60000 | loss 873.45229\n",
            "Episode  538 | test  | reward 317.55000 | loss 879.70661\n",
            "Episode  539 | test  | reward 317.45000 | loss 880.75292\n",
            "Episode  540 | test  | reward 316.25000 | loss 879.99186\n",
            "Episode  541 | test  | reward 314.80000 | loss 878.51060\n",
            "Episode  542 | test  | reward 314.30000 | loss 876.38823\n",
            "Episode  543 | test  | reward 316.35000 | loss 875.99219\n",
            "Episode  544 | test  | reward 316.55000 | loss 873.42361\n",
            "Episode  545 | test  | reward 315.40000 | loss 870.93430\n",
            "Episode  546 | test  | reward 317.70000 | loss 871.05551\n",
            "Episode  547 | test  | reward 317.70000 | loss 873.12090\n",
            "Episode  548 | test  | reward 316.95000 | loss 876.01628\n",
            "Episode  549 | test  | reward 320.25000 | loss 877.06158\n",
            "Episode  550 | test  | reward 321.40000 | loss 881.66054\n",
            "Episode  551 | test  | reward 320.60000 | loss 882.94100\n",
            "Episode  552 | test  | reward 318.50000 | loss 881.19961\n",
            "Episode  553 | test  | reward 317.80000 | loss 881.64149\n",
            "Episode  554 | test  | reward 316.75000 | loss 881.05833\n",
            "Episode  555 | test  | reward 316.00000 | loss 879.82920\n",
            "Episode  556 | test  | reward 318.20000 | loss 880.06868\n",
            "Episode  557 | test  | reward 319.65000 | loss 881.55069\n",
            "Episode  558 | test  | reward 320.10000 | loss 878.15404\n",
            "Episode  559 | test  | reward 320.60000 | loss 882.00747\n",
            "Episode  560 | test  | reward 322.85000 | loss 883.59419\n",
            "Episode  561 | test  | reward 322.50000 | loss 882.93941\n",
            "Episode  562 | test  | reward 322.55000 | loss 883.53712\n",
            "Episode  563 | test  | reward 320.20000 | loss 884.27587\n",
            "Episode  564 | test  | reward 320.85000 | loss 888.00072\n",
            "Episode  565 | test  | reward 319.40000 | loss 886.49046\n",
            "Episode  566 | test  | reward 318.25000 | loss 884.68411\n",
            "Episode  567 | test  | reward 315.80000 | loss 886.38805\n",
            "Episode  568 | test  | reward 315.90000 | loss 886.41645\n",
            "Episode  569 | test  | reward 315.25000 | loss 885.27808\n",
            "Episode  570 | test  | reward 315.10000 | loss 886.45738\n",
            "Episode  571 | test  | reward 312.85000 | loss 885.90571\n",
            "Episode  572 | test  | reward 313.05000 | loss 884.07535\n",
            "Episode  573 | test  | reward 312.45000 | loss 889.18786\n",
            "Episode  574 | test  | reward 312.90000 | loss 891.12838\n",
            "Episode  575 | test  | reward 314.45000 | loss 892.49912\n",
            "Episode  576 | test  | reward 314.60000 | loss 892.50973\n",
            "Episode  577 | test  | reward 314.25000 | loss 890.96681\n",
            "Episode  578 | test  | reward 314.90000 | loss 890.46714\n",
            "Episode  579 | test  | reward 314.90000 | loss 891.63903\n",
            "Episode  580 | test  | reward 316.70000 | loss 889.33242\n",
            "Episode  581 | test  | reward 315.05000 | loss 888.71160\n",
            "Episode  582 | test  | reward 312.00000 | loss 888.47913\n",
            "Episode  583 | test  | reward 310.60000 | loss 884.85566\n",
            "Episode  584 | test  | reward 309.80000 | loss 886.82144\n",
            "Episode  585 | test  | reward 309.00000 | loss 885.56917\n",
            "Episode  586 | test  | reward 307.70000 | loss 884.79906\n",
            "Episode  587 | test  | reward 308.00000 | loss 883.87047\n",
            "Episode  588 | test  | reward 309.05000 | loss 885.66108\n",
            "Episode  589 | test  | reward 308.75000 | loss 883.02772\n",
            "Episode  590 | test  | reward 308.25000 | loss 882.79093\n",
            "Episode  591 | test  | reward 309.85000 | loss 882.74470\n",
            "Episode  592 | test  | reward 313.65000 | loss 886.32710\n",
            "Episode  593 | test  | reward 312.40000 | loss 888.65791\n",
            "Episode  594 | test  | reward 309.90000 | loss 887.56026\n",
            "Episode  595 | test  | reward 312.50000 | loss 887.06815\n",
            "Episode  596 | test  | reward 313.20000 | loss 885.52023\n",
            "Episode  597 | test  | reward 313.45000 | loss 885.24561\n",
            "Episode  598 | test  | reward 312.35000 | loss 882.54916\n",
            "Episode  599 | test  | reward 311.90000 | loss 882.07021\n",
            "Episode  600 | test  | reward 313.90000 | loss 883.49781\n",
            "Episode  601 | test  | reward 313.65000 | loss 883.58758\n",
            "Episode  602 | test  | reward 314.75000 | loss 885.57055\n",
            "Episode  603 | test  | reward 315.25000 | loss 885.78384\n",
            "Episode  604 | test  | reward 317.20000 | loss 885.74581\n",
            "Episode  605 | test  | reward 317.50000 | loss 886.38930\n",
            "Episode  606 | test  | reward 317.50000 | loss 886.54004\n",
            "Episode  607 | test  | reward 315.75000 | loss 880.61622\n",
            "Episode  608 | test  | reward 315.85000 | loss 877.94860\n",
            "Episode  609 | test  | reward 314.85000 | loss 877.59805\n",
            "Episode  610 | test  | reward 314.40000 | loss 880.33261\n",
            "Episode  611 | test  | reward 313.85000 | loss 875.16271\n",
            "Episode  612 | test  | reward 312.95000 | loss 875.78519\n",
            "Episode  613 | test  | reward 313.00000 | loss 875.24268\n",
            "Episode  614 | test  | reward 314.50000 | loss 876.38196\n",
            "Episode  615 | test  | reward 312.55000 | loss 874.85038\n",
            "Episode  616 | test  | reward 314.80000 | loss 876.10248\n",
            "Episode  617 | test  | reward 311.70000 | loss 879.86668\n",
            "Episode  618 | test  | reward 313.60000 | loss 882.61139\n",
            "Episode  619 | test  | reward 317.40000 | loss 886.13436\n",
            "Episode  620 | test  | reward 317.30000 | loss 885.20503\n",
            "Episode  621 | test  | reward 316.10000 | loss 884.01260\n",
            "Episode  622 | test  | reward 316.15000 | loss 883.79165\n",
            "Episode  623 | test  | reward 316.55000 | loss 880.92709\n",
            "Episode  624 | test  | reward 317.60000 | loss 881.48887\n",
            "Episode  625 | test  | reward 319.35000 | loss 884.23744\n",
            "Episode  626 | test  | reward 320.05000 | loss 888.29342\n",
            "Episode  627 | test  | reward 321.05000 | loss 889.04229\n",
            "Episode  628 | test  | reward 320.75000 | loss 887.20319\n",
            "Episode  629 | test  | reward 321.05000 | loss 887.53724\n",
            "Episode  630 | test  | reward 320.95000 | loss 884.54683\n",
            "Episode  631 | test  | reward 318.35000 | loss 881.60623\n",
            "Episode  632 | test  | reward 315.90000 | loss 876.96506\n",
            "Episode  633 | test  | reward 315.80000 | loss 876.91931\n",
            "Episode  634 | test  | reward 314.60000 | loss 876.97319\n",
            "Episode  635 | test  | reward 314.85000 | loss 876.21051\n",
            "Episode  636 | test  | reward 316.15000 | loss 874.99731\n",
            "Episode  637 | test  | reward 316.65000 | loss 870.25481\n",
            "Episode  638 | test  | reward 317.00000 | loss 866.19503\n",
            "Episode  639 | test  | reward 315.85000 | loss 866.87852\n",
            "Episode  640 | test  | reward 317.15000 | loss 866.87120\n",
            "Episode  641 | test  | reward 314.65000 | loss 865.48586\n",
            "Episode  642 | test  | reward 315.90000 | loss 867.90721\n",
            "Episode  643 | test  | reward 315.00000 | loss 863.17385\n",
            "Episode  644 | test  | reward 314.25000 | loss 865.90997\n",
            "Episode  645 | test  | reward 317.70000 | loss 868.68347\n",
            "Episode  646 | test  | reward 317.30000 | loss 867.69653\n",
            "Episode  647 | test  | reward 319.55000 | loss 866.88986\n",
            "Episode  648 | test  | reward 319.35000 | loss 863.14709\n",
            "Episode  649 | test  | reward 317.90000 | loss 864.32292\n",
            "Episode  650 | test  | reward 319.60000 | loss 862.18567\n",
            "Episode  651 | test  | reward 320.15000 | loss 864.61110\n",
            "Episode  652 | test  | reward 320.75000 | loss 867.61906\n",
            "Episode  653 | test  | reward 321.10000 | loss 866.42808\n",
            "Episode  654 | test  | reward 321.95000 | loss 867.89979\n",
            "Episode  655 | test  | reward 325.00000 | loss 867.77686\n",
            "Episode  656 | test  | reward 323.50000 | loss 867.97423\n",
            "Episode  657 | test  | reward 321.05000 | loss 868.55706\n",
            "Episode  658 | test  | reward 320.60000 | loss 868.94502\n",
            "Episode  659 | test  | reward 321.65000 | loss 868.95643\n",
            "Episode  660 | test  | reward 320.45000 | loss 872.06274\n",
            "Episode  661 | test  | reward 320.10000 | loss 876.35127\n",
            "Episode  662 | test  | reward 320.00000 | loss 873.28243\n",
            "Episode  663 | test  | reward 321.10000 | loss 871.91613\n",
            "Episode  664 | test  | reward 320.70000 | loss 871.78725\n",
            "Episode  665 | test  | reward 320.05000 | loss 870.87880\n",
            "Episode  666 | test  | reward 320.60000 | loss 871.89634\n",
            "Episode  667 | test  | reward 322.50000 | loss 871.96895\n",
            "Episode  668 | test  | reward 323.15000 | loss 871.47333\n",
            "Episode  669 | test  | reward 322.80000 | loss 869.89081\n",
            "Episode  670 | test  | reward 322.55000 | loss 870.54221\n",
            "Episode  671 | test  | reward 322.80000 | loss 871.91276\n",
            "Episode  672 | test  | reward 324.35000 | loss 873.59841\n",
            "Episode  673 | test  | reward 324.20000 | loss 871.20884\n",
            "Episode  674 | test  | reward 322.75000 | loss 868.37809\n",
            "Episode  675 | test  | reward 322.90000 | loss 867.21640\n",
            "Episode  676 | test  | reward 320.45000 | loss 864.50030\n",
            "Episode  677 | test  | reward 320.55000 | loss 864.75089\n",
            "Episode  678 | test  | reward 320.05000 | loss 865.67995\n",
            "Episode  679 | test  | reward 318.55000 | loss 863.57266\n",
            "Episode  680 | test  | reward 317.55000 | loss 862.28214\n",
            "Episode  681 | test  | reward 318.75000 | loss 864.24641\n",
            "Episode  682 | test  | reward 321.65000 | loss 863.56481\n",
            "Episode  683 | test  | reward 323.00000 | loss 867.15044\n",
            "Episode  684 | test  | reward 323.95000 | loss 866.64527\n",
            "Episode  685 | test  | reward 324.65000 | loss 866.78244\n",
            "Episode  686 | test  | reward 327.30000 | loss 868.68912\n",
            "Episode  687 | test  | reward 328.20000 | loss 870.71489\n",
            "Episode  688 | test  | reward 328.25000 | loss 874.29527\n",
            "Episode  689 | test  | reward 328.70000 | loss 875.51925\n",
            "Episode  690 | test  | reward 330.65000 | loss 874.68627\n",
            "Episode  691 | test  | reward 329.75000 | loss 872.16181\n",
            "Episode  692 | test  | reward 328.20000 | loss 870.77886\n",
            "Episode  693 | test  | reward 328.30000 | loss 871.43057\n",
            "Episode  694 | test  | reward 331.50000 | loss 868.31060\n",
            "Episode  695 | test  | reward 327.40000 | loss 869.03390\n",
            "Episode  696 | test  | reward 327.75000 | loss 867.97705\n",
            "Episode  697 | test  | reward 328.30000 | loss 868.51760\n",
            "Episode  698 | test  | reward 331.45000 | loss 872.11460\n",
            "Episode  699 | test  | reward 333.70000 | loss 873.60322\n",
            "Episode  700 | test  | reward 333.90000 | loss 874.01925\n",
            "Episode  701 | test  | reward 333.70000 | loss 874.88162\n",
            "Episode  702 | test  | reward 330.70000 | loss 873.75330\n",
            "Episode  703 | test  | reward 329.55000 | loss 874.39439\n",
            "Episode  704 | test  | reward 328.95000 | loss 878.06213\n",
            "Episode  705 | test  | reward 328.55000 | loss 878.82138\n",
            "Episode  706 | test  | reward 326.30000 | loss 877.58439\n",
            "Episode  707 | test  | reward 327.60000 | loss 879.65292\n",
            "Episode  708 | test  | reward 328.30000 | loss 882.33955\n",
            "Episode  709 | test  | reward 330.25000 | loss 881.08859\n",
            "Episode  710 | test  | reward 330.05000 | loss 881.15350\n",
            "Episode  711 | test  | reward 330.25000 | loss 883.40230\n",
            "Episode  712 | test  | reward 330.60000 | loss 884.99752\n",
            "Episode  713 | test  | reward 331.00000 | loss 884.38819\n",
            "Episode  714 | test  | reward 330.75000 | loss 883.75645\n",
            "Episode  715 | test  | reward 333.10000 | loss 885.83966\n",
            "Episode  716 | test  | reward 331.25000 | loss 882.77105\n",
            "Episode  717 | test  | reward 329.65000 | loss 881.09099\n",
            "Episode  718 | test  | reward 326.70000 | loss 878.15667\n",
            "Episode  719 | test  | reward 327.30000 | loss 878.85740\n",
            "Episode  720 | test  | reward 327.25000 | loss 878.52682\n",
            "Episode  721 | test  | reward 328.70000 | loss 879.59175\n",
            "Episode  722 | test  | reward 328.70000 | loss 879.44253\n",
            "Episode  723 | test  | reward 327.95000 | loss 880.92233\n",
            "Episode  724 | test  | reward 326.35000 | loss 878.88567\n",
            "Episode  725 | test  | reward 326.20000 | loss 880.12983\n",
            "Episode  726 | test  | reward 325.80000 | loss 880.52246\n",
            "Episode  727 | test  | reward 326.50000 | loss 878.90342\n",
            "Episode  728 | test  | reward 326.55000 | loss 876.86067\n",
            "Episode  729 | test  | reward 325.50000 | loss 878.83689\n",
            "Episode  730 | test  | reward 325.50000 | loss 879.24144\n",
            "Episode  731 | test  | reward 325.95000 | loss 880.08528\n",
            "Episode  732 | test  | reward 326.55000 | loss 882.37681\n",
            "Episode  733 | test  | reward 327.35000 | loss 881.61510\n",
            "Episode  734 | test  | reward 326.85000 | loss 881.43092\n",
            "Episode  735 | test  | reward 326.65000 | loss 883.69368\n",
            "Episode  736 | test  | reward 324.25000 | loss 890.28680\n",
            "Episode  737 | test  | reward 322.35000 | loss 888.37645\n",
            "Episode  738 | test  | reward 321.35000 | loss 890.07958\n",
            "Episode  739 | test  | reward 323.70000 | loss 889.80035\n",
            "Episode  740 | test  | reward 324.30000 | loss 887.58824\n",
            "Episode  741 | test  | reward 324.25000 | loss 888.63698\n",
            "Episode  742 | test  | reward 323.45000 | loss 886.14015\n",
            "Episode  743 | test  | reward 325.60000 | loss 887.84387\n",
            "Episode  744 | test  | reward 329.00000 | loss 887.78415\n",
            "Episode  745 | test  | reward 329.05000 | loss 887.66472\n",
            "Episode  746 | test  | reward 329.25000 | loss 887.75557\n",
            "Episode  747 | test  | reward 325.50000 | loss 885.29409\n",
            "Episode  748 | test  | reward 326.30000 | loss 885.33573\n",
            "Episode  749 | test  | reward 326.15000 | loss 882.17703\n",
            "Episode  750 | test  | reward 326.60000 | loss 881.41711\n",
            "Episode  751 | test  | reward 327.20000 | loss 879.87113\n",
            "Episode  752 | test  | reward 327.10000 | loss 876.59986\n",
            "Episode  753 | test  | reward 328.30000 | loss 878.15346\n",
            "Episode  754 | test  | reward 328.75000 | loss 875.88804\n",
            "Episode  755 | test  | reward 326.05000 | loss 875.52363\n",
            "Episode  756 | test  | reward 324.10000 | loss 874.33611\n",
            "Episode  757 | test  | reward 324.20000 | loss 876.84689\n",
            "Episode  758 | test  | reward 322.55000 | loss 876.48526\n",
            "Episode  759 | test  | reward 321.95000 | loss 877.18171\n",
            "Episode  760 | test  | reward 322.60000 | loss 875.11565\n",
            "Episode  761 | test  | reward 322.85000 | loss 871.94279\n",
            "Episode  762 | test  | reward 322.90000 | loss 871.90913\n",
            "Episode  763 | test  | reward 323.10000 | loss 873.05865\n",
            "Episode  764 | test  | reward 324.35000 | loss 872.23726\n",
            "Episode  765 | test  | reward 326.45000 | loss 874.59682\n",
            "Episode  766 | test  | reward 328.40000 | loss 875.60835\n",
            "Episode  767 | test  | reward 328.00000 | loss 874.24859\n",
            "Episode  768 | test  | reward 328.30000 | loss 873.58538\n",
            "Episode  769 | test  | reward 329.75000 | loss 877.16738\n",
            "Episode  770 | test  | reward 330.20000 | loss 875.81969\n",
            "Episode  771 | test  | reward 328.95000 | loss 873.55659\n",
            "Episode  772 | test  | reward 327.95000 | loss 872.14380\n",
            "Episode  773 | test  | reward 327.20000 | loss 867.96842\n",
            "Episode  774 | test  | reward 328.55000 | loss 869.89432\n",
            "Episode  775 | test  | reward 328.70000 | loss 871.48272\n",
            "Episode  776 | test  | reward 331.10000 | loss 874.38584\n",
            "Episode  777 | test  | reward 331.30000 | loss 874.42474\n",
            "Episode  778 | test  | reward 329.50000 | loss 875.01779\n",
            "Episode  779 | test  | reward 328.10000 | loss 875.16391\n",
            "Episode  780 | test  | reward 326.55000 | loss 874.99273\n",
            "Episode  781 | test  | reward 325.35000 | loss 873.81573\n",
            "Episode  782 | test  | reward 324.45000 | loss 878.32851\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0e3bb0618536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_test_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mepisode_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mupdate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-c326fe578f33>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(curr_step, buffer, is_training)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mepisode_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-c326fe578f33>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0monline_dqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monline_dqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-02edc50c4f27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mout3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mout4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  plot_metrics(metrics)"
      ],
      "metadata": {
        "id": "RQbMdor_dCnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}